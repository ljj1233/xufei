# Agent Environment Configuration Example
# Xunfei API Configuration
XUNFEI_APPID=cbb008fd
XUNFEI_API_KEY=32171beeed3829345a0b5a14189fd8b3
XUNFEI_API_SECRET=YjIyY2RkZjg5ZmY0ZmEyOGI5NmExOTFk

# Xunfei Service URLs
XUNFEI_ISE_URL=https://api.xfyun.cn/v1/service/v1/ise
XUNFEI_IAT_URL=https://api.xfyun.cn/v1/service/v1/iat
XUNFEI_EMOTION_URL=https://api.xf-yun.cn/v1/service/v1/emotion

# LLM Service Configuration (New)
# ModelScope Configuration
OPENAI_API_KEY=2e2308bb-976a-4ea7-badd-0ab1bf2066bd
OPENAI_API_BASE=https://api-inference.modelscope.cn/v1/
OPENAI_MODEL=Qwen/Qwen2.5-7B-Instruct

# Spark Big Model Configuration (New)
SPARK_APPID=cbb008fd
SPARK_API_KEY=32171beeed3829345a0b5a14189fd8b3
SPARK_API_SECRET=YjIyY2RkZjg5ZmY0ZmEyOGI5NmExOTFk
SPARK_API_URL=wss://spark-api.xf-yun.com/v1.1/chat

# LLM Provider Selection (New)
# Options: modelscope, xunfei
LLM_PROVIDER=modelscope

# Question Generation Service Configuration
QUESTION_CACHE_EXPIRATION=3600  # Cache expiration time in seconds
QUESTION_GENERATION_MODEL=Qwen/Qwen2.5-7B-Instruct  # Model for question generation
